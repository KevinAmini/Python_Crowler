{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "82c26d87",
   "metadata": {},
   "source": [
    "#load all libraries which are necessary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8303ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import validators\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "76e6be33",
   "metadata": {},
   "source": [
    "# Define global variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "217547c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "url='http://www.cnn.com'\n",
    "list_total=[]\n",
    "rank=1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb840654",
   "metadata": {},
   "source": [
    "# define recursive function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "35f6831d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Crowl(url):\n",
    "    counter1=0\n",
    "    list_add=[]                                            #Storing external link in each page\n",
    "    global rank\n",
    "    print(\"the current url is:\", url)                      #It is a current url which crowled \n",
    "    print(\"the stack of urls crowlered are:\\n\",list_total) #It shows the all of external link which are cowled until now\n",
    "    if rank<10:                                            #It is a depth of corowling variable which sets 10  \n",
    "        try:                                               #Using the structure to handel any incident of crowling web address \n",
    "            reqs=urllib.request.urlopen(url)               # Opening the web site and storing to variable\n",
    "            Soup=BeautifulSoup(reqs,'html.parser')         #Parsing the web site \n",
    "            Refrenc=Soup.find_all('a')                     #Focusing on <a> tag on web site \n",
    "        except:\n",
    "            print(\"The url should be changed\")             #Presenting the error message when the url can not open  \n",
    "            url=list_total.pop()                           #Deleting the url which can not open it for any reasons \n",
    "            url\n",
    "\n",
    "        for link in Refrenc:                               #Looking a external link in web site \n",
    "             if link.get('href') is not None:              #Checking that url does not becomes no suitable string\n",
    "                if(validators.url(link.get('href'))):      #Checking that url is correct format \n",
    "                    list_add.append(link.get('href'))      #Storing an external link to list \n",
    "        print(\"the length of list of links is:\",len(list_add))# Pirinting the result of this operation via the length of list which external links\n",
    "        mylist = list(dict.fromkeys(list_add))             # Removing duplicat links \n",
    "        print(\"the length of reduced list is:\",len(mylist))#Printing the total external links that are reduced \n",
    "\n",
    "        try:\n",
    "            counter1=0                                     #Selecting randomly from list_add(list of all external link) \n",
    "            select_list=[]                                 #The list which is stores url selected \n",
    "            select_index=0                                 #It is an Index of selection \n",
    "            for i in mylist:                               #Traversing of reduced list \n",
    "                        if i!=url:                         #To avoid to create loop, it is necessary to check the external become external links \n",
    "                            select_list.append(i)          #Adding to select list \n",
    "            select_index=random.randint(0, (len(select_list))) #Choosing the next external link randomly from the selected links \n",
    "            print(\"the length of my list is:\",len(mylist)) #Printing the length of reduced list \n",
    "            print(\"the length of short list is :\",len(select_list))#Printing the the lenghth of final short list of the external lists\n",
    "            print(\"the last url is:\",url,\"new url is:\",select_list[select_index])#Printing the last Url and new Url\n",
    "            url=select_list[select_index]                  #subsitute new url for crowling \n",
    "            list_total.append(url)                         #add url to the list of Crowled links \n",
    "        except:                                            #If for any reasons it can not find the external link follow these code   \n",
    "            print(\"The url should be changed\")             #Present the error message  \n",
    "            url=list_total.pop()                           #Remove the url which has a problem \n",
    "        rank+=1                                            #Increasing the depth parameter \n",
    "        print(\"the depth of crowler is:\",rank)             #Printing the depth parameter \n",
    "        Crowl(url)                                         #Call recursion function to  continue crowling \n",
    "    else:\n",
    "         print(\"corwler is finished\")                      #if depth of crowling meat the defined value the program is finished "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e90dbff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the current url is: http://www.cnn.com\n",
      "the stack of urls crowlered are:\n",
      " []\n",
      "the length of list of links is: 22\n",
      "the length of reduced list is: 12\n",
      "the length of my list is: 12\n",
      "the length of short list is : 12\n",
      "the last url is: http://www.cnn.com new url is: https://bleacherreport.com/nfl\n",
      "the depth of crowler is: 2\n",
      "the current url is: https://bleacherreport.com/nfl\n",
      "the stack of urls crowlered are:\n",
      " ['https://bleacherreport.com/nfl']\n",
      "the length of list of links is: 88\n",
      "the length of reduced list is: 68\n",
      "the length of my list is: 68\n",
      "the length of short list is : 68\n",
      "the last url is: https://bleacherreport.com/nfl new url is: https://bleacherreport.com/videos/406354-ranking-top-10-teams-in-nfl\n",
      "the depth of crowler is: 3\n",
      "the current url is: https://bleacherreport.com/videos/406354-ranking-top-10-teams-in-nfl\n",
      "the stack of urls crowlered are:\n",
      " ['https://bleacherreport.com/nfl', 'https://bleacherreport.com/videos/406354-ranking-top-10-teams-in-nfl']\n",
      "the length of list of links is: 10\n",
      "the length of reduced list is: 7\n",
      "the length of my list is: 7\n",
      "the length of short list is : 7\n",
      "the last url is: https://bleacherreport.com/videos/406354-ranking-top-10-teams-in-nfl new url is: https://br.app.link/kvlitRF9Dqb\n",
      "the depth of crowler is: 4\n",
      "the current url is: https://br.app.link/kvlitRF9Dqb\n",
      "the stack of urls crowlered are:\n",
      " ['https://bleacherreport.com/nfl', 'https://bleacherreport.com/videos/406354-ranking-top-10-teams-in-nfl', 'https://br.app.link/kvlitRF9Dqb']\n",
      "the length of list of links is: 0\n",
      "the length of reduced list is: 0\n",
      "the length of my list is: 0\n",
      "the length of short list is : 0\n",
      "The url should be changed\n",
      "the depth of crowler is: 5\n",
      "the current url is: https://br.app.link/kvlitRF9Dqb\n",
      "the stack of urls crowlered are:\n",
      " ['https://bleacherreport.com/nfl', 'https://bleacherreport.com/videos/406354-ranking-top-10-teams-in-nfl']\n",
      "the length of list of links is: 0\n",
      "the length of reduced list is: 0\n",
      "the length of my list is: 0\n",
      "the length of short list is : 0\n",
      "The url should be changed\n",
      "the depth of crowler is: 6\n",
      "the current url is: https://bleacherreport.com/videos/406354-ranking-top-10-teams-in-nfl\n",
      "the stack of urls crowlered are:\n",
      " ['https://bleacherreport.com/nfl']\n",
      "the length of list of links is: 10\n",
      "the length of reduced list is: 7\n",
      "the length of my list is: 7\n",
      "the length of short list is : 7\n",
      "The url should be changed\n",
      "the depth of crowler is: 7\n",
      "the current url is: https://bleacherreport.com/nfl\n",
      "the stack of urls crowlered are:\n",
      " []\n",
      "the length of list of links is: 88\n",
      "the length of reduced list is: 68\n",
      "the length of my list is: 68\n",
      "the length of short list is : 68\n",
      "the last url is: https://bleacherreport.com/nfl new url is: https://twitter.com/brgridiron/status/1638629088360542215\n",
      "the depth of crowler is: 8\n",
      "the current url is: https://twitter.com/brgridiron/status/1638629088360542215\n",
      "the stack of urls crowlered are:\n",
      " ['https://twitter.com/brgridiron/status/1638629088360542215']\n",
      "the length of list of links is: 6\n",
      "the length of reduced list is: 6\n",
      "the length of my list is: 6\n",
      "the length of short list is : 6\n",
      "the last url is: https://twitter.com/brgridiron/status/1638629088360542215 new url is: https://business.twitter.com/en/help/troubleshooting/how-twitter-ads-work.html?ref=web-twc-ao-gbl-adsinfo&utm_source=twc&utm_medium=web&utm_campaign=ao&utm_content=adsinfo\n",
      "the depth of crowler is: 9\n",
      "the current url is: https://business.twitter.com/en/help/troubleshooting/how-twitter-ads-work.html?ref=web-twc-ao-gbl-adsinfo&utm_source=twc&utm_medium=web&utm_campaign=ao&utm_content=adsinfo\n",
      "the stack of urls crowlered are:\n",
      " ['https://twitter.com/brgridiron/status/1638629088360542215', 'https://business.twitter.com/en/help/troubleshooting/how-twitter-ads-work.html?ref=web-twc-ao-gbl-adsinfo&utm_source=twc&utm_medium=web&utm_campaign=ao&utm_content=adsinfo']\n",
      "the length of list of links is: 53\n",
      "the length of reduced list is: 52\n",
      "the length of my list is: 52\n",
      "the length of short list is : 52\n",
      "the last url is: https://business.twitter.com/en/help/troubleshooting/how-twitter-ads-work.html?ref=web-twc-ao-gbl-adsinfo&utm_source=twc&utm_medium=web&utm_campaign=ao&utm_content=adsinfo new url is: https://privacy.twitter.com/\n",
      "the depth of crowler is: 10\n",
      "the current url is: https://privacy.twitter.com/\n",
      "the stack of urls crowlered are:\n",
      " ['https://twitter.com/brgridiron/status/1638629088360542215', 'https://business.twitter.com/en/help/troubleshooting/how-twitter-ads-work.html?ref=web-twc-ao-gbl-adsinfo&utm_source=twc&utm_medium=web&utm_campaign=ao&utm_content=adsinfo', 'https://privacy.twitter.com/']\n",
      "corwler is finished\n"
     ]
    }
   ],
   "source": [
    "#url=inpute(\"please enter the URL with the correct format:\")#There is capability for asking the user to enter url for crowling\n",
    "#rank=int(input(\"Please choose the depth of crowling:\"))    #There is capability for asking the user to enter the depth of crowling \n",
    "Crowl(url)                                                 #Calling first time function with define "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0a0d95d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://cnnnewsource.com',\n",
       " 'https://www.cnnnewsource.com/latest-insights/',\n",
       " 'https://www.cnnnewsource.com/in-the-classroom/',\n",
       " 'https://twitter.com/cnnnewsource',\n",
       " 'https://legal.twitter.com/imprint.html',\n",
       " 'https://twitter.com/privacy',\n",
       " 'https://help.twitter.com/managing-your-account/connect-or-revoke-access-to-third-party-apps?lang=browser',\n",
       " 'https://help.twitter.com/en/managing-your-account/forgotten-or-lost-password-reset',\n",
       " 'https://blog.twitter.com/developer/']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_total                                              #presenting the list of urls which is crowled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5881b9ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
